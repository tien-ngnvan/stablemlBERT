# stablemlBERT
Pretrain BERT models support Asia Multilingual by modifying architecture use Attention with Linear Biases (ALiBi) and FlashAttention
